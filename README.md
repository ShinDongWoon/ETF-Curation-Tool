# 금융 포트폴리오 분석 시스템: NH투자증권 데이터 및 LLM 활용 연구

## 1. 서론 (Introduction)

현대 금융 시장에서 개인 투자자의 합리적 의사결정은 방대한 정보의 효과적인 처리와 분석 능력에 크게 의존한다. 그러나 개인 투자자가 접근 가능한 데이터의 양이 증가함에도 불구하고, 이를 체계적으로 분석하고 투자 전략에 반영하는 데에는 여전히 간극이 존재한다. 본 연구는 이러한 문제의식에서 출발하여, NH투자증권에서 제공된 실제 금융 빅데이터와 공개 시장 데이터를 통합하고, 여기에 최근 주목받는 대규모 언어 모델(LLM)을 접목함으로써 개인 투자자를 위한 지능형 포트폴리오 분석 및 진단 시스템 프로토타입을 개발하고자 하였다.

본 시스템은 단순한 금융 지표 계산을 넘어, NH투자증권 고객 데이터를 활용한 독자적인 "심리적 위험 지수"와 같은 새로운 분석 관점을 제시한다. 또한, OpenAI의 GPT 모델을 통해 정량적 분석 결과에 대한 정성적 해석과 개인화된 조언을 생성함으로써, 데이터 기반 의사결정의 실질적인 효용성을 탐색하고자 하였다. 연구 과정에서 AI 코딩 어시스턴트(Claude)가 프로토타이핑 단계에서 보조 도구로 활용되었으나, 시스템의 전체 아키텍처 설계, 핵심 금융 로직의 정의 및 검증, 그리고 최종 디버깅은 연구 주체에 의해 주도적으로 수행되었음을 밝힌다.

본 연구의 목적은 개인 투자자가 자신의 포트폴리오를 보다 객관적이고 다각적으로 이해하며, 잠재적 위험 요인을 인지하고, 나아가 합리적인 투자 전략을 수립하는 데 실질적인 도움을 줄 수 있는 시스템의 가능성을 제시하는 데 있다.

## 2. 연구 방법론 (Methodology)

본 시스템은 데이터 수집 및 전처리, 핵심 금융 지표 산출, 포트폴리오 심층 분석, 그리고 LLM 기반 조언 생성의 단계로 구성된다.

### 2.1. 데이터 수집 및 전처리 (Data Acquisition and Preprocessing)

* **데이터 원천 (Data Sources)**:
    * NH투자증권 제공 데이터: 종목 기본 정보, 일별 시세, NH 고객 투자 현황, 배당 내역, ETF Z-score 및 구성종목 정보 등 공모전 제공 데이터 일체.
    * Yahoo Finance API (`yfinance`): 시장 벤치마크로 S&P 500 지수(`^GSPC`) 활용.
    * 사용자 입력: 분석 대상 포트폴리오 구성(티커, 비중, 평균 매입 단가)을 `cumulative_portfolio.csv` 파일 형태로 가정.
* **전처리 (Preprocessing)**:
    * `chardet` 라이브러리를 이용한 CSV 파일 인코딩 자동 감지 및 `pandas` DataFrame으로의 로딩.
    * 데이터 타입 정제(날짜형, 수치형 변환), 문자열 공백 제거 등 기본적인 데이터 클리닝 수행.
    * 분석 편의성 및 가독성을 위해 원본 컬럼명을 연구자가 이해하기 용이한 한글명으로 매핑.
    * 수익률 계산: 포트폴리오 지표 산출 시에는 로그 수익률($R_t = \ln(P_t/P_{t-1})$)을 주로 사용하였으며, 개별 주식 리스크 지표에서는 단순 수익률($R_t = (P_t - P_{t-1})/P_{t-1}$)을 일부 활용하였다. **수익률 정의의 일관성 및 각 지표 계산 시 적합성 검토는 향후 중요한 개선 과제로 인식하고 있다.**

### 2.2. 핵심 금융 지표 산출 (Core Financial Metrics Calculation)

본 연구에서는 표준적인 금융 이론에 기반하여 개별 자산 및 포트폴리오 수준의 위험-수익 특성을 평가하기 위한 지표들을 산출하였다. 단, 일부 지표는 현재 프로토타입의 구현상 간략화되었거나 표준 정의와 차이가 있을 수 있음을 인지하고 있으며, 이는 "5. 연구의 한계 및 향후 과제"에서 상세히 논한다.

* **개별 주식 분석 지표 (`calculate_risk_metrics`)**:
    * 연간 수익률 및 변동성 (단순 일일 수익률 기반).
    * 샤프 지수 (Sharpe Ratio): $S_a = (R_a - R_f) / \sigma_a$.
    * Value at Risk (VaR, 5%): 일별 수익률 분포의 하위 5% 분위수. (현 코드에서는 `CVaR (5%)`로 명명되어 있으나, 실제 산식은 VaR에 해당함).
* **포트폴리오 분석 지표 (`calculate_portfolio_metrics`)**:
    * 포트폴리오 연간 수익률 및 변동성 (로그 수익률 기반).
    * 포트폴리오 베타($\beta_p$): 현재 구현에서는 개별 종목 수익률의 단순 합계를 포트폴리오 수익률로 간주하여 시장 벤치마크와의 공분산을 계산하고 있어, **자산별 가중치를 반영한 포트폴리오 수익률 기반의 $\beta_p$ 계산으로의 수정이 필요하다.**
    * 트레이너 비율 (Treynor Ratio): 상기 $\beta_p$ 값의 정확성에 의존.
    * 정보 비율 (Information Ratio, IR): $\beta_p$ 와 유사하게, 초과 수익률 계산 시 포트폴리오 가중치 적용이 미비함.
    * 최대 낙폭 (Max Drawdown, MDD) 및 CDaR (95%).
    * 기대 부족분 (Expected Shortfall, ES 5%): 현재는 포트폴리오 내 개별 자산 수익률의 하위 5% 값들의 평균을 다시 평균하는 방식으로, **포트폴리오 전체 수익률 분포 기반의 표준 ES 정의와는 차이가 있다.**
* **무위험 이자율 ($R_f$)**: 분석의 일관성을 위해 `0.037`로 가정하였으나, 실제 분석 시점의 시장 금리(예: 단기 국채 수익률)를 반영하는 것이 바람직하다.

### 2.3. NH투자증권 고객 데이터 기반 분석 (NH Customer Data-Driven Analysis)

표준 금융 지표 외에, NH투자증권 고객 데이터를 활용하여 다음과 같은 독자적 분석을 시도하였다.

* **사용자 포지션 분석 (`analyze_user_position`)**: 투자자의 평균 매입 단가를 NH 고객 전체의 매입 단가 분포(10분위 기준)와 비교하여, 상대적 진입 가격 수준 및 현재의 미실현 손익 상태를 가늠할 수 있도록 하였다.
* **심리적 위험 지수 (`calculate_psychological_risk_index`)**: 사용자의 평균 매입 단가가 NH 고객 분포상 어느 분위에 해당하는지에 따라 1점에서 10점까지의 점수를 부여하는 지표이다 ($Index = 10 - 2 \times N$, $N$: 분포 분위 그룹 인덱스). 이는 투자자가 상대적으로 높은 가격에 매수했을 가능성, 혹은 그로 인한 심리적 부담감을 간접적으로 시사할 수 있다는 가정에서 출발하였다. 이 지수의 실증적 유효성에 대해서는 추가 연구가 필요하다.
* **투자자 심리 분석 (`analyze_investor_sentiment`)**: NH 데이터 내 '수익투자자비율'을 활용하여 시장 참여자들의 전반적인 투자 심리를 5단계로 범주화하였다.

### 2.4. LLM 기반 개인화 조언 생성 (LLM-Powered Personalized Advice Generation)

본 연구의 핵심적인 시도 중 하나는 정량적 분석 결과를 바탕으로 개인 투자자에게 맞춤형 해석과 조언을 제공하는 것이다.

* **OpenAI GPT-3.5-Turbo 연동**: `openai` 라이브러리를 통해 GPT 모델 API를 호출한다.
* **프롬프트 설계**: 사용자의 투자자 프로파일(4분면 분석 결과), 주요 포트폴리오 지표, 추천 ETF 후보군 등을 구조화된 형태로 LLM에 전달한다. 시스템 메시지를 통해 LLM에게 "금융 자문가"의 역할을 부여하고, 제공된 데이터를 기반으로 상세하고 개인화된 분석 및 조언을 생성하도록 요청한다. 현재 프롬프트는 초기 형태로, 향후 고도화가 필요하다.
* **결과물**: LLM이 생성한 자연어 형태의 포트폴리오 진단 및 투자 제언. API 호출 제한(Rate Limit) 등 잠재적 오류에 대한 기본적인 예외 처리 로직을 포함한다.

## 3. 시스템 구현 (System Implementation)

### 3.1. 개발 환경 (Environment)

* **플랫폼**: Google Colaboratory (Python 3)
* **주요 라이브러리**: `numpy`, `pandas`, `matplotlib`, `seaborn`, `yfinance`, `chardet`, `openai`, `google.colab.drive`.
* (권장 사항: `requirements.txt`를 통한 체계적인 의존성 관리)

### 3.2. 코드 구조 (Code Architecture)

* `StockData (dataclass)`: 개별 종목의 다양한 정보를 통합 관리하기 위한 데이터 구조.
* `EnhancedStockAnalyzer (class)`: 데이터 로딩, 전처리, 지표 계산, 분석, 시각화 등 핵심 로직을 포함하는 메인 클래스.
    * `__init__`: Google Drive 마운트, 데이터 파일 경로 초기화 및 `load_data()`를 통한 데이터 적재.
    * `_load_data`: `chardet` 기반 CSV 파일 로딩 유틸리티.
    * `get_..._info`: 데이터 유형별 정보 추출.
    * `calculate_..._metrics`: 각종 금융 지표 계산.
    * `analyze_...`: NH 고객 데이터 기반 분석 및 심리 지표 산출.
    * `plot_...`: Matplotlib/Seaborn 기반 시각화.
    * `update_result_dataframe`: 분석 결과를 클래스 내부 DataFrame(`self.result_df`)에 기록.
* **독립 함수 (Helper Functions)**:
    * `classify_etf`: ETF Z-score 기반 4분면 분류.
    * `filter_low_performance_investments`: 특정 재무 지표(Beta, PBR, PER) 기준 저성과 추정 종목 필터링.
    * `analyze_portfolio_position`: 포트폴리오의 Sharpe Ratio 및 Information Ratio 기반 4분면 분석.
    * `generate_personalized_analysis`: OpenAI API 호출 및 조언 생성.
* `main()`: 전체 분석 파이프라인 실행 및 사용자 인터랙션을 위한 CLI(Command Line Interface) 제공.

### 3.3. 실행 가이드 (Execution Guide for Google Colab)

1.  **OpenAI API 키 설정 (필수)**:
    * **보안 경고**: 코드 내에 API 키를 직접 문자열로 삽입하는 것은 매우 위험하다.
    * **권장**: Google Colab의 'Secrets' 기능을 활용. `OPENAI_API_KEY`라는 이름으로 키를 저장하고, `userdata.get('OPENAI_API_KEY')`를 통해 코드에서 안전하게 접근하도록 한다. (예시 코드는 이전 답변 참조)
2.  **데이터 파일 준비**:
    * Google Drive 내 특정 경로에 NH투자증권 제공 CSV 파일 및 사용자 포트폴리오 파일(`cumulative_portfolio.csv`)을 위치시킨다.
    * `EnhancedStockAnalyzer` 클래스 내 `self.file_paths`와 `main` 함수의 `file_path` 변수를 실제 경로에 맞게 수정한다.
3.  **Google Drive 마운트**: 코드 실행 시 `drive.mount('/content/drive')`를 통해 Google Drive 접근 권한을 획득한다.
4.  **라이브러리 설치**: 필요한 경우, `!pip install ...` 명령어를 사용하여 Colab 환경에 라이브러리를 설치한다.
5.  **스크립트 실행**: Colab 노트북 셀에서 코드를 실행한다. 초기 포트폴리오 분석 후, 투자자 ID 입력을 통해 대화형 분석 및 조언 생성이 가능하다.

## 4. 주요 분석 결과 및 논의 (Key Findings and Discussion)

시스템 실행을 통해 도출되는 주요 결과는 다음과 같다.

* **정량적 분석 결과**: 개별 종목 및 포트폴리오 전체에 대한 위험-수익 지표, NH 고객 데이터 기반의 상대적 포지션 및 심리 지표 등이 `result_df` DataFrame 형태로 제공된다.
* **시각화 자료**: 주요 지표 간의 관계(예: 심리적 위험 지수 vs. Sharpe Ratio), 분포, 상/하위 종목 등을 직관적으로 파악할 수 있는 그래프들이 생성된다.
* **ETF 분류 및 저성과 추정 종목**: 특정 기준에 따른 ETF 그룹핑 및 잠재적 개선 대상 종목 식별 결과를 제공한다.
* **LLM 생성 조언**: 상기 분석 결과들을 종합하여, 사용자의 투자 성향 및 포트폴리오 상태에 대한 자연어 기반의 해석과 구체적인 행동 제안을 포함하는 조언이 생성된다.

**결과에 대한 논의**:
본 시스템이 제공하는 다층적 분석 정보는 투자자가 자신의 포트폴리오를 보다 깊이 있게 이해하는 데 기여할 수 있다. 특히, 표준 금융 지표와 더불어 NH 고객 데이터를 활용한 "심리적 위험 지수" 등은 투자 결정 과정에서의 행동 편향 가능성을 환기시키는 등 새로운 관점을 제공할 잠재력을 가진다. LLM을 통해 생성된 조언은 복잡한 수치 데이터를 사용자가 쉽게 이해하고 실제 행동으로 연결하는 데 도움을 줄 수 있다는 점에서 긍정적이다.

그러나 **결과 해석 시 유의점**이 존재한다. 첫째, LLM이 생성하는 조언은 어디까지나 입력된 데이터와 프롬프트에 기반한 확률적 생성물이며, 그 정확성이나 모든 상황에 대한 적합성을 보장할 수 없다. 따라서 이는 **투자의 참고 자료로만 활용되어야 하며, 어떠한 경우에도 금융 자문으로 간주되어서는 안 된다.** 둘째, 과거 데이터 기반의 분석은 미래 성과를 보장하지 않으며, 금융 시장의 본질적인 불확실성을 고려해야 한다. 셋째, 본 연구에서 사용된 일부 금융 지표의 계산 방식은 학술적 표준과 차이가 있을 수 있으므로(5절 참조), 결과의 절대적 수치보다는 상대적 비교나 추세 파악에 중점을 두는 것이 바람직하다.

## 5. 연구의 한계 및 향후 과제 (Limitations and Future Research Directions)

본 연구는 프로토타입 개발 단계로서 다음과 같은 명확한 한계점을 내포하며, 이는 향후 연구를 통해 개선될 필요가 있다.

* **금융 지표 계산의 엄밀성**:
    * **최우선 개선 과제**: 포트폴리오 베타($\beta_p$), 정보비율(IR), 기대부족분(ES) 등 핵심 지표들의 계산 로직이 학술적 표준 정의와 일부 괴리가 있다(2.2절 참조). 이는 분석 결과의 신뢰성에 직접적인 영향을 미치므로, **이론적 근거에 기반한 정밀한 검토 및 코드 수정이 시급하다.**
    * VaR와 CVaR(ES) 용어 사용의 혼동을 바로잡고, 필요시 실제 CVaR(ES) 계산 로직을 구현해야 한다.
    * 수익률 계산 방식(로그 수익률 vs. 단순 수익률)의 적용 기준을 명확히 하고, 분석 목적에 따른 일관성을 확보해야 한다.
* **보안**: OpenAI API 키 관리의 중요성을 강조하였으나, 코드 배포 및 공유 시에는 더욱 견고한 보안 대책이 요구된다.
* **환경 의존성 및 재현성**: Google Colab 및 특정 Google Drive 경로에 대한 의존성을 줄이고, 일반 Python 환경에서의 실행 용이성 및 연구 재현성을 높이기 위한 노력이 필요하다 (예: 설정 파일 도입, 상대 경로 사용).
* **LLM 프롬프트 엔지니어링**: 현재의 프롬프트는 LLM의 잠재력을 충분히 활용하기에는 다소 단순하다. 문맥 이해도, 답변의 구체성 및 일관성을 높이기 위한 고급 프롬프트 엔지니어링 기법(예: 역할 플레이 강화, 단계별 지시, Few-shot 예시 제공, 출력 형식 명시 등)의 적용이 요구된다.
* **소프트웨어 공학적 완성도**: `EnhancedStockAnalyzer` 클래스의 단일 책임 원칙(SRP) 위배, `main` 함수의 복잡성 등은 코드의 유지보수성 및 확장성을 저해할 수 있다. 객체 지향 설계 원칙에 따른 리팩토링 및 모듈화가 필요하다.
* **테스팅 부재**: 핵심 금융 로직 및 주요 기능에 대한 단위 테스트(Unit Test)의 부재는 코드의 신뢰성을 담보하기 어렵게 만든다. 특히 금융 계산의 정확성은 매우 중요하므로, 테스트 코드 작성이 필수적이다.
* **자체 개발 지표의 실증적 검증**: "심리적 위험 지수"와 같은 자체 개발 지표는 흥미로운 시도이나, 그 타당성과 유효성에 대한 통계적 검증 및 학술적 논의가 뒷받침되어야 한다.
* **예외 처리**: 현재 구현된 예외 처리 로직은 API 호출 등 일부에 국한되어 있어, 데이터 로딩, 전처리, 계산 과정 등 전반에 걸쳐 보다 견고하고 세분화된 예외 처리 강화가 필요하다.

**향후 연구 방향**:
본 연구의 한계를 극복하고 시스템을 발전시키기 위한 향후 연구 방향은 다음과 같다.
1.  **금융 모델링의 정교화**: 표준 금융 이론에 부합하는 지표 계산 로직을 확립하고, 나아가 다변량 분석, 요인 모델(Factor Models), 시계열 분석 등 고급 계량 금융 기법을 도입하여 분석의 깊이를 더한다.
2.  **머신러닝/딥러닝의 접목**: 시장 예측, 이상치 탐지, 투자자 행동 패턴 분석, 강화학습 기반의 동적 포트폴리오 최적화 등 머신러닝 및 딥러닝 모델을 통합하여 시스템의 예측 및 추천 기능을 고도화한다.
3.  **사용자 인터페이스 및 경험(UI/UX) 개선**: 현재의 CLI 기반 인터페이스를 넘어, Streamlit, Dash, 또는 웹 프레임워크(Flask/Django)를 활용하여 사용자가 보다 직관적이고 인터랙티브하게 시스템을 활용할 수 있도록 개선한다.
4.  **백테스팅 프레임워크 구축**: 개발된 포트폴리오 전략이나 LLM의 조언이 과거 특정 기간 동안 어떤 성과를 보였을지 시뮬레이션할 수 있는 견고한 백테스팅 환경을 구축하여 전략의 유효성을 검증한다.
5.  **대안 데이터(Alternative Data)의 활용**: 뉴스 기사, 소셜 미디어 게시물, 기업 공시 자료 등 비정형 텍스트 데이터에 대한 자연어 처리(NLP) 및 감성 분석을 수행하고, 이를 LLM의 입력 정보로 활용하거나 새로운 분석 지표로 개발하여 시장의 미묘한 변화나 투자자 심리를 포착한다.
6.  **시스템 설정의 유연성 확보**: 파일 경로, API 키 참조 방식, 주요 분석 파라미터 등을 외부 설정 파일(예: `config.ini`, `config.yaml`)을 통해 관리하도록 변경하여 시스템의 이식성과 사용자 정의 가능성을 높인다.

## 6. 결론 (Conclusion)

본 연구는 NH투자증권 제공 금융 빅데이터와 LLM이라는 새로운 기술을 접목하여, 개인 투자자를 위한 지능형 포트폴리오 분석 시스템의 프로토타입을 개발하고 그 가능성을 탐색하였다. AI 코딩 어시스턴트와의 효율적인 협업을 통해 아이디어를 신속하게 구현하였으며, 기존의 정량적 분석에 더하여 NH 고객 데이터 기반의 독창적 지표 및 LLM을 통한 개인화된 자연어 조언 생성 기능을 통합함으로써, 금융 분석 도구의 새로운 방향성을 제시하고자 하였다.

그러나 프로토타입 단계인 만큼, 특히 금융 지표 계산의 학술적 엄밀성 확보, 시스템의 견고성 및 보안 강화, LLM 활용 전략의 고도화 등은 향후 반드시 해결해야 할 중요한 과제이다. 이러한 과제들을 극복하고 지속적인 연구 개발을 통해 본 시스템이 개인 투자자들의 합리적 의사결정을 지원하고 금융 시장 이해도를 제고하는 데 실질적으로 기여할 수 있기를 기대한다.

## 7. 연구자 정보 (Author / Contributor)

* [사용자님의 이름 또는 닉네임]
* [소속 (학교/학과 또는 개인 프로젝트 명시)]
* [GitHub 프로필 링크 또는 이메일 주소 (선택 사항)]
* **AI 협업 명시**: 본 연구 프로토타입의 일부 코드 초안 작성 및 아이디어 구체화 과정에서 AI 코딩 어시스턴트(Claude by Anthropic)가 보조 도구로 활용되었음을 밝힌다. 프로젝트의 전체적인 설계, 핵심 금융 로직의 정의 및 검증, 최종 디버깅 및 본 보고서 작성은 연구 주체에 의해 수행되었다.

## 8. 라이선스 (License)

[프로젝트의 라이선스를 명시합니다. 예: MIT License, Apache License 2.0 또는 "For educational/research purposes only." 등. 공모전 제출물인 경우 해당 규정을 따릅니다.]

